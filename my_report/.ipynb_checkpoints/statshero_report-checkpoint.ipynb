{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9c27df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file location:C:/Users/int_shansiming/Desktop/Prediction/salary.xlsx\n",
      "Enter your requestanalyze the data\n",
      "In what language do you wish your report to be?English\n",
      "Select your x from (['代码', '科室名称', '工号', '姓名\\u3000', '计奖人数', '科室奖金分配']): 科室名称\n",
      "Select your y from (['代码', '科室名称', '工号', '姓名\\u3000', '计奖人数', '科室奖金分配']): 科室奖金分配\n",
      "Enter your desired plot typebar plot\n",
      "bar plot, A bar plot is a graph that shows the frequency or number of occurrences of different categories of data. Bar plots are used to compare data between different groups, or to show how data has changed over time.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xbf in position 279: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[32], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgenerated_code\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mrunpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenerated_code.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py:287\u001b[0m, in \u001b[0;36mrun_path\u001b[1;34m(path_name, init_globals, run_name)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(importer, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;129;01mor\u001b[39;00m is_NullImporter:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Not a valid sys.path entry, so run the code directly\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# execfile() doesn't help as we want to allow compiled files\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     code, fname \u001b[38;5;241m=\u001b[39m \u001b[43m_get_code_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _run_module_code(code, init_globals, run_name,\n\u001b[0;32m    289\u001b[0m                             pkg_name\u001b[38;5;241m=\u001b[39mpkg_name, script_name\u001b[38;5;241m=\u001b[39mfname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py:257\u001b[0m, in \u001b[0;36m_get_code_from_file\u001b[1;34m(run_name, fname)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen_code(decoded_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 257\u001b[0m         code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m code, fname\n",
      "\u001b[1;31mSyntaxError\u001b[0m: invalid syntax (generated_code.py, line 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\int_shansiming\\pycharmprojects\\aiproject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2040\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(etype, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n\u001b[0;32m   2038\u001b[0m     \u001b[38;5;66;03m# Though this won't be called by syntax errors in the input\u001b[39;00m\n\u001b[0;32m   2039\u001b[0m     \u001b[38;5;66;03m# line, there may be SyntaxError cases with imported code.\u001b[39;00m\n\u001b[1;32m-> 2040\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowsyntaxerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_compiled_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m UsageError:\n\u001b[0;32m   2042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_usage_error(value)\n",
      "File \u001b[1;32mc:\\users\\int_shansiming\\pycharmprojects\\aiproject\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2115\u001b[0m, in \u001b[0;36mInteractiveShell.showsyntaxerror\u001b[1;34m(self, filename, running_compiled_code)\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;66;03m# If the error occurred when executing compiled code, we should provide full stacktrace.\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m elist \u001b[38;5;241m=\u001b[39m traceback\u001b[38;5;241m.\u001b[39mextract_tb(last_traceback) \u001b[38;5;28;01mif\u001b[39;00m running_compiled_code \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m-> 2115\u001b[0m stb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSyntaxTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showtraceback(etype, value, stb)\n",
      "File \u001b[1;32mc:\\users\\int_shansiming\\pycharmprojects\\aiproject\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py:1324\u001b[0m, in \u001b[0;36mSyntaxTB.structured_traceback\u001b[1;34m(self, etype, value, elist, tb_offset, context)\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;167;01mSyntaxError\u001b[39;00m) \\\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;28mstr\u001b[39m) \\\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mlineno, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1323\u001b[0m     linecache\u001b[38;5;241m.\u001b[39mcheckcache(value\u001b[38;5;241m.\u001b[39mfilename)\n\u001b[1;32m-> 1324\u001b[0m     newtext \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m newtext:\n\u001b[0;32m   1326\u001b[0m         value\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m newtext\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\linecache.py:137\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tokenize\u001b[38;5;241m.\u001b[39mopen(fullname) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m--> 137\u001b[0m         lines \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xbf in position 279: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Import all necessary packages\n",
    "import openai\n",
    "import runpy\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "path = \"C:/Users/int_shansiming/Desktop/Prediction/Nasdaq.csv\"\n",
    "path2 = \"C:/Users/int_shansiming/Desktop/Prediction/data.csv\"\n",
    "path3 = \"C:/Users/int_shansiming/Desktop/Prediction/DailyDelhiClimateTest.csv\"\n",
    "path4 = \"C:/Users/int_shansiming/Desktop/Prediction/salary.xlsx\"\n",
    "\n",
    "\n",
    "# Set up the parameters for the GPT-3 API\n",
    "model = \"text-davinci-002\"\n",
    "temperature_1 = 0.1\n",
    "temperature_2 = 1\n",
    "max_tokens = 3000\n",
    "\n",
    "# Ask for file location\n",
    "user_input_file = input(\"Enter the file location:\")\n",
    "\n",
    "# import the data\n",
    "try:\n",
    "    user_data=pd.read_csv(user_input_file)\n",
    "except ValueError:\n",
    "    user_data=pd.read_excel(user_input_file)\n",
    "\n",
    "# Then get the column names\n",
    "col_name = user_data.columns.tolist()\n",
    "\n",
    "# Ask user for input\n",
    "user_input_1 = input(\"Enter your request\")\n",
    "\n",
    "# Language setting\n",
    "user_language = input(\"In what language do you wish your report to be?\")\n",
    "\n",
    "# Ask for features if the user ask for a plot\n",
    "if any(keyword in user_input_1 for keyword in [\"plot\", \"graph\", \"analyze\", \"analysis\"]):\n",
    "    features_x = input(f\"Select your x from ({col_name}): \")\n",
    "    features_y = input(f\"Select your y from ({col_name}): \")\n",
    "    method = input(\"Enter your desired plot type\")\n",
    "else:\n",
    "    user_input_1 = user_input_1\n",
    "\n",
    "# Introduce the plot type\n",
    "# Check if the input contains any keywords\n",
    "if any(keyword in user_input_1 for keyword in [\"plot\", \"graph\", \"analyze\", \"analysis\"]):\n",
    "    prompt = f'''Introduce {method} and explain how they are used in data analysis  in {user_language}.'''\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature_1,\n",
    "    )\n",
    "\n",
    "print(f\"{method}, {response.choices[0].text.strip()}\")\n",
    "\n",
    "# Check if the input contains any keywords\n",
    "if any(keyword in user_input_1 for keyword in [\"plot\", \"graph\", \"analyze\", \"analysis\"]):\n",
    "    prompt = f\"Generate Python code that does the following steps:\\\n",
    "    1. Import cleaning.py and use the cleaning.clean() function to import and clean the dataset from {user_input_file}, and then save it as 'df'.\\\n",
    "    2. Import matplotlib.pyplot as plt and generate a {method} to display the relationship between x = {features_x} and {features_y}.\\\n",
    "    3. Add a title to the graph using the Matplotlib library.\\\n",
    "    4. If there are two features in {features_y}, add a legend.\\\n",
    "    5. Label the axes using appropriate units based on the names of the features.\\\n",
    "    6. Follow the above prompt strictly. Do not include any notes or numbering in the code.\"\n",
    "\n",
    "    # Generate code using the GPT-3 API\n",
    "    response = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature_1,\n",
    "    )\n",
    "\n",
    "    # Save the generated code to a file\n",
    "    with open(\"generated_code.py\", \"w\") as f:\n",
    "        f.write(response.choices[0].text.strip())\n",
    "\n",
    "    # Import the generated code as a module\n",
    "    import generated_code\n",
    "\n",
    "    runpy.run_path('generated_code.py')\n",
    "\n",
    "else:\n",
    "    prompt = f'''{user_input_1}, The file is from: {user_input_file}'''\n",
    "    response = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature_1,\n",
    "    )\n",
    "    print(response.choices[0].text.strip())\n",
    "\n",
    "# Using openai api to generate a comprehensive report\n",
    "user_input_file = pd.read_csv(user_input_file)\n",
    "prompt_text = f'''\n",
    "Please provide a comprehensive data analysis report for the following dataset:\n",
    "\n",
    "{user_input_file}\n",
    "\n",
    "The report should include:\n",
    "\n",
    "1. Overview of the dataset: Briefly describe the dataset (how many observations there are), its variables, and their meanings.\n",
    "2. Descriptive statistics (mean, median, mode, standard deviation, etc.) for each variable\n",
    "3. Identification of any potential outliers or missing values\n",
    "4. Correlations between variables and their significance\n",
    "5. Identify trends, patterns, correlations, or anomalies in the data and describe their significance.\n",
    "\n",
    "And the report should be in {user_language}\n",
    "\n",
    "Please present the findings in a clear, precise, and professional manner.\n",
    "'''\n",
    "\n",
    "response_text = openai.Completion.create(\n",
    "    engine=model,\n",
    "    prompt=prompt_text,\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=temperature_2,\n",
    ")\n",
    "print(f'''{response_text.choices[0].text.strip()}''')\n",
    "\n",
    "prompt_text = f'''\n",
    "Please provide the required data analysis report in {user_language} for the following dataset:\n",
    "\n",
    "{user_input_file}\n",
    "\n",
    "The report should include:\n",
    "\n",
    "1. Analyze {features_x} and {features_y} using relevant statistical learning techniques(like regression or ARIMA)\n",
    "2. Build the model and display the result parameter, and explain its meaning(Do not show the code)\n",
    "3. Recommendations for further analysis\n",
    "\n",
    "\n",
    "Please present the findings in a clear, precise, and professional manner.\n",
    "'''\n",
    "\n",
    "response_text = openai.Completion.create(\n",
    "    engine=model,\n",
    "    prompt=prompt_text,\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=temperature_2,\n",
    ")\n",
    "print(f'''{response_text.choices[0].text.strip()}''')\n",
    "\n",
    "path3 = \"C:/Users/int_shansiming/Desktop/Prediction/DailyDelhiClimateTest.csv\"\n",
    "path4 = \"C:/Users/int_shansiming/Desktop/Prediction/salary.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84eea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
